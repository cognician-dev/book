# guardrailing

Many we speak to are opposed to it on fundamental, economic, or ecological grounds, but we use AI in our development workflows. We do not trust the AI to commit code that we do not, as professionals, understand. What AI is good for, however, largely, is boilerplating. Humans are slow typers. The cognitive task of designing the inner workings of software, analytical or otherwise, is in tension, we find, with the mechanical task of typing code according to strict syntax rules which are easy to forget and unstable from language to language and framework to framework. 

This document is here to serve a dual purpose. To, when expanded, give our readers and visitors a glimpse into our philosophy, and to serve as a foundational (though certainly not comprehensive) set of guardrails used to constrain the probabilistic behavior of many of the models we employ.

